{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78deac-d13f-4332-9ff4-b29d1c519bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "#Replace with the server's actual IP and port\n",
    "url = \"http://127.0.0.1:8000/process\"\n",
    "\n",
    "#Path to the image you want to upload\n",
    "image_file = \"assets/framework.png\"  # Replace with the path to your image file\n",
    "\n",
    "#Open the image file and send it as part of a POST request\n",
    "with open(image_file, \"rb\") as f:\n",
    "    files = {\"file\": f}\n",
    "    response = requests.post(url, files=files)\n",
    "\n",
    "#Print the response from the server\n",
    "if response.status_code == 200:\n",
    "    print(\"Label:\", response.json())\n",
    "else:\n",
    "    print(\"Failed to process image:\", response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b250e5a-21d2-4b00-b056-f0645e61082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT EDIT !!!\n",
    "\n",
    "# import requests\n",
    "\n",
    "\n",
    "# url = \"http://127.0.0.1:8000/upload-video/\"  # Replace <server-ip> with the server's IP\n",
    "# #files = {'file': open('test.jpeg', 'rb')}  # Replace 'image.jpg' with your file path\n",
    "\n",
    "# # response = requests.post(url, files=files)\n",
    "# # if response.status_code == 200:\n",
    "# #     print(\"Result:\", response.json())\n",
    "# # else:\n",
    "# #     print(\"Error:\", response.text)\n",
    "\n",
    "# # Specify the video file to upload\n",
    "# video_file = \"clientVid2.mp4\"  # Replace with your local video file path\n",
    "\n",
    "# # Upload the video file\n",
    "# with open(video_file, \"rb\") as f:\n",
    "#     files = {\"file\": f}\n",
    "#     response = requests.post(url, files=files)\n",
    "\n",
    "# # Print the server's response\n",
    "# if response.status_code == 200:\n",
    "#     print(\"Upload successful:\", response.json())\n",
    "# else:\n",
    "#     print(\"Upload failed:\", response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7290e38-56bf-4e73-8d65-c7b7ee34d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07eb9492-f31c-428e-bdb1-24eef1dd3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms._transforms_video as transforms_video\n",
    "from moviepy.editor import *\n",
    "#from transformers import AutoTokenizer\n",
    "#from tqdm import tqdm\n",
    "#import argparse\n",
    "\n",
    "from src.data.video_transforms import Permute\n",
    "from src.models.video_recap import VideoRecap\n",
    "from src.data.datasets import VideoCaptionDataset, CaptionDataCollator\n",
    "from src.models.timesformer import SpaceTimeTransformer\n",
    "#from src.models.openai_model import QuickGELU\n",
    "#from src.configs.defaults import defaultConfigs\n",
    "#from PIL import Image\n",
    "#import pickle\n",
    "#from io import BytesIO\n",
    "\n",
    "import requests\n",
    "import base64\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.responses import JSONResponse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "203ecb0d-79fa-4d3a-adda-13c384eda705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save uploaded videos\n",
    "UPLOAD_DIRECTORY = \"assets\"\n",
    "os.makedirs(UPLOAD_DIRECTORY, exist_ok=True)\n",
    "\n",
    "# Specify the video file to upload\n",
    "video_file = \"clientVid1\"  # Replace with your local video file path\n",
    "\n",
    "# Save the uploaded video file\n",
    "# file_path = os.path.join(UPLOAD_DIRECTORY, file.filename)\n",
    "# with open(file_path, \"wb\") as f:\n",
    "#     f.write(await file.read())\n",
    "#vid = os.path.splitext(file.filename)[0]\n",
    "vid = video_file #temporary solution, needs to be fixed\n",
    "video_file = f'assets/{vid}.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de15d6ef-0978-461e-8bb9-5a11f16aca74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Creating model\n",
      "######USING ATTENTION STYLE:  frozen-in-time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.crossattention.output.LayerNorm.bias', 'encoder.layer.0.crossattention.output.LayerNorm.weight', 'encoder.layer.0.crossattention.output.dense.bias', 'encoder.layer.0.crossattention.output.dense.weight', 'encoder.layer.0.crossattention.self.key.bias', 'encoder.layer.0.crossattention.self.key.weight', 'encoder.layer.0.crossattention.self.query.bias', 'encoder.layer.0.crossattention.self.query.weight', 'encoder.layer.0.crossattention.self.value.bias', 'encoder.layer.0.crossattention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate_query.dense.bias', 'encoder.layer.0.intermediate_query.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output_query.LayerNorm.bias', 'encoder.layer.0.output_query.LayerNorm.weight', 'encoder.layer.0.output_query.dense.bias', 'encoder.layer.0.output_query.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate_query.dense.bias', 'encoder.layer.1.intermediate_query.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output_query.LayerNorm.bias', 'encoder.layer.1.output_query.LayerNorm.weight', 'encoder.layer.1.output_query.dense.bias', 'encoder.layer.1.output_query.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.crossattention.output.LayerNorm.bias', 'encoder.layer.10.crossattention.output.LayerNorm.weight', 'encoder.layer.10.crossattention.output.dense.bias', 'encoder.layer.10.crossattention.output.dense.weight', 'encoder.layer.10.crossattention.self.key.bias', 'encoder.layer.10.crossattention.self.key.weight', 'encoder.layer.10.crossattention.self.query.bias', 'encoder.layer.10.crossattention.self.query.weight', 'encoder.layer.10.crossattention.self.value.bias', 'encoder.layer.10.crossattention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate_query.dense.bias', 'encoder.layer.10.intermediate_query.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output_query.LayerNorm.bias', 'encoder.layer.10.output_query.LayerNorm.weight', 'encoder.layer.10.output_query.dense.bias', 'encoder.layer.10.output_query.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate_query.dense.bias', 'encoder.layer.11.intermediate_query.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output_query.LayerNorm.bias', 'encoder.layer.11.output_query.LayerNorm.weight', 'encoder.layer.11.output_query.dense.bias', 'encoder.layer.11.output_query.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.crossattention.output.LayerNorm.bias', 'encoder.layer.2.crossattention.output.LayerNorm.weight', 'encoder.layer.2.crossattention.output.dense.bias', 'encoder.layer.2.crossattention.output.dense.weight', 'encoder.layer.2.crossattention.self.key.bias', 'encoder.layer.2.crossattention.self.key.weight', 'encoder.layer.2.crossattention.self.query.bias', 'encoder.layer.2.crossattention.self.query.weight', 'encoder.layer.2.crossattention.self.value.bias', 'encoder.layer.2.crossattention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate_query.dense.bias', 'encoder.layer.2.intermediate_query.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output_query.LayerNorm.bias', 'encoder.layer.2.output_query.LayerNorm.weight', 'encoder.layer.2.output_query.dense.bias', 'encoder.layer.2.output_query.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate_query.dense.bias', 'encoder.layer.3.intermediate_query.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output_query.LayerNorm.bias', 'encoder.layer.3.output_query.LayerNorm.weight', 'encoder.layer.3.output_query.dense.bias', 'encoder.layer.3.output_query.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.crossattention.output.LayerNorm.bias', 'encoder.layer.4.crossattention.output.LayerNorm.weight', 'encoder.layer.4.crossattention.output.dense.bias', 'encoder.layer.4.crossattention.output.dense.weight', 'encoder.layer.4.crossattention.self.key.bias', 'encoder.layer.4.crossattention.self.key.weight', 'encoder.layer.4.crossattention.self.query.bias', 'encoder.layer.4.crossattention.self.query.weight', 'encoder.layer.4.crossattention.self.value.bias', 'encoder.layer.4.crossattention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate_query.dense.bias', 'encoder.layer.4.intermediate_query.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output_query.LayerNorm.bias', 'encoder.layer.4.output_query.LayerNorm.weight', 'encoder.layer.4.output_query.dense.bias', 'encoder.layer.4.output_query.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate_query.dense.bias', 'encoder.layer.5.intermediate_query.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output_query.LayerNorm.bias', 'encoder.layer.5.output_query.LayerNorm.weight', 'encoder.layer.5.output_query.dense.bias', 'encoder.layer.5.output_query.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.crossattention.output.LayerNorm.bias', 'encoder.layer.6.crossattention.output.LayerNorm.weight', 'encoder.layer.6.crossattention.output.dense.bias', 'encoder.layer.6.crossattention.output.dense.weight', 'encoder.layer.6.crossattention.self.key.bias', 'encoder.layer.6.crossattention.self.key.weight', 'encoder.layer.6.crossattention.self.query.bias', 'encoder.layer.6.crossattention.self.query.weight', 'encoder.layer.6.crossattention.self.value.bias', 'encoder.layer.6.crossattention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate_query.dense.bias', 'encoder.layer.6.intermediate_query.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output_query.LayerNorm.bias', 'encoder.layer.6.output_query.LayerNorm.weight', 'encoder.layer.6.output_query.dense.bias', 'encoder.layer.6.output_query.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate_query.dense.bias', 'encoder.layer.7.intermediate_query.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output_query.LayerNorm.bias', 'encoder.layer.7.output_query.LayerNorm.weight', 'encoder.layer.7.output_query.dense.bias', 'encoder.layer.7.output_query.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.crossattention.output.LayerNorm.bias', 'encoder.layer.8.crossattention.output.LayerNorm.weight', 'encoder.layer.8.crossattention.output.dense.bias', 'encoder.layer.8.crossattention.output.dense.weight', 'encoder.layer.8.crossattention.self.key.bias', 'encoder.layer.8.crossattention.self.key.weight', 'encoder.layer.8.crossattention.self.query.bias', 'encoder.layer.8.crossattention.self.query.weight', 'encoder.layer.8.crossattention.self.value.bias', 'encoder.layer.8.crossattention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate_query.dense.bias', 'encoder.layer.8.intermediate_query.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output_query.LayerNorm.bias', 'encoder.layer.8.output_query.LayerNorm.weight', 'encoder.layer.8.output_query.dense.bias', 'encoder.layer.8.output_query.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate_query.dense.bias', 'encoder.layer.9.intermediate_query.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output_query.LayerNorm.bias', 'encoder.layer.9.output_query.LayerNorm.weight', 'encoder.layer.9.output_query.dense.bias', 'encoder.layer.9.output_query.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freeze the pretrained parts in Bert: ['bert.embeddings.word_embeddings.weight', 'bert.embeddings.position_embeddings.weight', 'bert.embeddings.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.0.output.dense.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.0.intermediate_query.dense.weight', 'bert.encoder.layer.0.intermediate_query.dense.bias', 'bert.encoder.layer.0.output_query.dense.weight', 'bert.encoder.layer.0.output_query.dense.bias', 'bert.encoder.layer.0.output_query.LayerNorm.weight', 'bert.encoder.layer.0.output_query.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.weight', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.1.intermediate_query.dense.weight', 'bert.encoder.layer.1.intermediate_query.dense.bias', 'bert.encoder.layer.1.output_query.dense.weight', 'bert.encoder.layer.1.output_query.dense.bias', 'bert.encoder.layer.1.output_query.LayerNorm.weight', 'bert.encoder.layer.1.output_query.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate_query.dense.weight', 'bert.encoder.layer.2.intermediate_query.dense.bias', 'bert.encoder.layer.2.output_query.dense.weight', 'bert.encoder.layer.2.output_query.dense.bias', 'bert.encoder.layer.2.output_query.LayerNorm.weight', 'bert.encoder.layer.2.output_query.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate.dense.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.3.intermediate_query.dense.weight', 'bert.encoder.layer.3.intermediate_query.dense.bias', 'bert.encoder.layer.3.output_query.dense.weight', 'bert.encoder.layer.3.output_query.dense.bias', 'bert.encoder.layer.3.output_query.LayerNorm.weight', 'bert.encoder.layer.3.output_query.LayerNorm.bias', 'bert.encoder.layer.4.attention.self.query.weight', 'bert.encoder.layer.4.attention.self.query.bias', 'bert.encoder.layer.4.attention.self.key.weight', 'bert.encoder.layer.4.attention.self.key.bias', 'bert.encoder.layer.4.attention.self.value.weight', 'bert.encoder.layer.4.attention.self.value.bias', 'bert.encoder.layer.4.attention.output.dense.weight', 'bert.encoder.layer.4.attention.output.dense.bias', 'bert.encoder.layer.4.attention.output.LayerNorm.weight', 'bert.encoder.layer.4.attention.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate.dense.weight', 'bert.encoder.layer.4.intermediate.dense.bias', 'bert.encoder.layer.4.output.dense.weight', 'bert.encoder.layer.4.output.dense.bias', 'bert.encoder.layer.4.output.LayerNorm.weight', 'bert.encoder.layer.4.output.LayerNorm.bias', 'bert.encoder.layer.4.intermediate_query.dense.weight', 'bert.encoder.layer.4.intermediate_query.dense.bias', 'bert.encoder.layer.4.output_query.dense.weight', 'bert.encoder.layer.4.output_query.dense.bias', 'bert.encoder.layer.4.output_query.LayerNorm.weight', 'bert.encoder.layer.4.output_query.LayerNorm.bias', 'bert.encoder.layer.5.attention.self.query.weight', 'bert.encoder.layer.5.attention.self.query.bias', 'bert.encoder.layer.5.attention.self.key.weight', 'bert.encoder.layer.5.attention.self.key.bias', 'bert.encoder.layer.5.attention.self.value.weight', 'bert.encoder.layer.5.attention.self.value.bias', 'bert.encoder.layer.5.attention.output.dense.weight', 'bert.encoder.layer.5.attention.output.dense.bias', 'bert.encoder.layer.5.attention.output.LayerNorm.weight', 'bert.encoder.layer.5.attention.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate.dense.weight', 'bert.encoder.layer.5.intermediate.dense.bias', 'bert.encoder.layer.5.output.dense.weight', 'bert.encoder.layer.5.output.dense.bias', 'bert.encoder.layer.5.output.LayerNorm.weight', 'bert.encoder.layer.5.output.LayerNorm.bias', 'bert.encoder.layer.5.intermediate_query.dense.weight', 'bert.encoder.layer.5.intermediate_query.dense.bias', 'bert.encoder.layer.5.output_query.dense.weight', 'bert.encoder.layer.5.output_query.dense.bias', 'bert.encoder.layer.5.output_query.LayerNorm.weight', 'bert.encoder.layer.5.output_query.LayerNorm.bias', 'bert.encoder.layer.6.attention.self.query.weight', 'bert.encoder.layer.6.attention.self.query.bias', 'bert.encoder.layer.6.attention.self.key.weight', 'bert.encoder.layer.6.attention.self.key.bias', 'bert.encoder.layer.6.attention.self.value.weight', 'bert.encoder.layer.6.attention.self.value.bias', 'bert.encoder.layer.6.attention.output.dense.weight', 'bert.encoder.layer.6.attention.output.dense.bias', 'bert.encoder.layer.6.attention.output.LayerNorm.weight', 'bert.encoder.layer.6.attention.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate.dense.weight', 'bert.encoder.layer.6.intermediate.dense.bias', 'bert.encoder.layer.6.output.dense.weight', 'bert.encoder.layer.6.output.dense.bias', 'bert.encoder.layer.6.output.LayerNorm.weight', 'bert.encoder.layer.6.output.LayerNorm.bias', 'bert.encoder.layer.6.intermediate_query.dense.weight', 'bert.encoder.layer.6.intermediate_query.dense.bias', 'bert.encoder.layer.6.output_query.dense.weight', 'bert.encoder.layer.6.output_query.dense.bias', 'bert.encoder.layer.6.output_query.LayerNorm.weight', 'bert.encoder.layer.6.output_query.LayerNorm.bias', 'bert.encoder.layer.7.attention.self.query.weight', 'bert.encoder.layer.7.attention.self.query.bias', 'bert.encoder.layer.7.attention.self.key.weight', 'bert.encoder.layer.7.attention.self.key.bias', 'bert.encoder.layer.7.attention.self.value.weight', 'bert.encoder.layer.7.attention.self.value.bias', 'bert.encoder.layer.7.attention.output.dense.weight', 'bert.encoder.layer.7.attention.output.dense.bias', 'bert.encoder.layer.7.attention.output.LayerNorm.weight', 'bert.encoder.layer.7.attention.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate.dense.weight', 'bert.encoder.layer.7.intermediate.dense.bias', 'bert.encoder.layer.7.output.dense.weight', 'bert.encoder.layer.7.output.dense.bias', 'bert.encoder.layer.7.output.LayerNorm.weight', 'bert.encoder.layer.7.output.LayerNorm.bias', 'bert.encoder.layer.7.intermediate_query.dense.weight', 'bert.encoder.layer.7.intermediate_query.dense.bias', 'bert.encoder.layer.7.output_query.dense.weight', 'bert.encoder.layer.7.output_query.dense.bias', 'bert.encoder.layer.7.output_query.LayerNorm.weight', 'bert.encoder.layer.7.output_query.LayerNorm.bias', 'bert.encoder.layer.8.attention.self.query.weight', 'bert.encoder.layer.8.attention.self.query.bias', 'bert.encoder.layer.8.attention.self.key.weight', 'bert.encoder.layer.8.attention.self.key.bias', 'bert.encoder.layer.8.attention.self.value.weight', 'bert.encoder.layer.8.attention.self.value.bias', 'bert.encoder.layer.8.attention.output.dense.weight', 'bert.encoder.layer.8.attention.output.dense.bias', 'bert.encoder.layer.8.attention.output.LayerNorm.weight', 'bert.encoder.layer.8.attention.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate.dense.weight', 'bert.encoder.layer.8.intermediate.dense.bias', 'bert.encoder.layer.8.output.dense.weight', 'bert.encoder.layer.8.output.dense.bias', 'bert.encoder.layer.8.output.LayerNorm.weight', 'bert.encoder.layer.8.output.LayerNorm.bias', 'bert.encoder.layer.8.intermediate_query.dense.weight', 'bert.encoder.layer.8.intermediate_query.dense.bias', 'bert.encoder.layer.8.output_query.dense.weight', 'bert.encoder.layer.8.output_query.dense.bias', 'bert.encoder.layer.8.output_query.LayerNorm.weight', 'bert.encoder.layer.8.output_query.LayerNorm.bias', 'bert.encoder.layer.9.attention.self.query.weight', 'bert.encoder.layer.9.attention.self.query.bias', 'bert.encoder.layer.9.attention.self.key.weight', 'bert.encoder.layer.9.attention.self.key.bias', 'bert.encoder.layer.9.attention.self.value.weight', 'bert.encoder.layer.9.attention.self.value.bias', 'bert.encoder.layer.9.attention.output.dense.weight', 'bert.encoder.layer.9.attention.output.dense.bias', 'bert.encoder.layer.9.attention.output.LayerNorm.weight', 'bert.encoder.layer.9.attention.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate.dense.weight', 'bert.encoder.layer.9.intermediate.dense.bias', 'bert.encoder.layer.9.output.dense.weight', 'bert.encoder.layer.9.output.dense.bias', 'bert.encoder.layer.9.output.LayerNorm.weight', 'bert.encoder.layer.9.output.LayerNorm.bias', 'bert.encoder.layer.9.intermediate_query.dense.weight', 'bert.encoder.layer.9.intermediate_query.dense.bias', 'bert.encoder.layer.9.output_query.dense.weight', 'bert.encoder.layer.9.output_query.dense.bias', 'bert.encoder.layer.9.output_query.LayerNorm.weight', 'bert.encoder.layer.9.output_query.LayerNorm.bias', 'bert.encoder.layer.10.attention.self.query.weight', 'bert.encoder.layer.10.attention.self.query.bias', 'bert.encoder.layer.10.attention.self.key.weight', 'bert.encoder.layer.10.attention.self.key.bias', 'bert.encoder.layer.10.attention.self.value.weight', 'bert.encoder.layer.10.attention.self.value.bias', 'bert.encoder.layer.10.attention.output.dense.weight', 'bert.encoder.layer.10.attention.output.dense.bias', 'bert.encoder.layer.10.attention.output.LayerNorm.weight', 'bert.encoder.layer.10.attention.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate.dense.weight', 'bert.encoder.layer.10.intermediate.dense.bias', 'bert.encoder.layer.10.output.dense.weight', 'bert.encoder.layer.10.output.dense.bias', 'bert.encoder.layer.10.output.LayerNorm.weight', 'bert.encoder.layer.10.output.LayerNorm.bias', 'bert.encoder.layer.10.intermediate_query.dense.weight', 'bert.encoder.layer.10.intermediate_query.dense.bias', 'bert.encoder.layer.10.output_query.dense.weight', 'bert.encoder.layer.10.output_query.dense.bias', 'bert.encoder.layer.10.output_query.LayerNorm.weight', 'bert.encoder.layer.10.output_query.LayerNorm.bias', 'bert.encoder.layer.11.attention.self.query.weight', 'bert.encoder.layer.11.attention.self.query.bias', 'bert.encoder.layer.11.attention.self.key.weight', 'bert.encoder.layer.11.attention.self.key.bias', 'bert.encoder.layer.11.attention.self.value.weight', 'bert.encoder.layer.11.attention.self.value.bias', 'bert.encoder.layer.11.attention.output.dense.weight', 'bert.encoder.layer.11.attention.output.dense.bias', 'bert.encoder.layer.11.attention.output.LayerNorm.weight', 'bert.encoder.layer.11.attention.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate.dense.weight', 'bert.encoder.layer.11.intermediate.dense.bias', 'bert.encoder.layer.11.output.dense.weight', 'bert.encoder.layer.11.output.dense.bias', 'bert.encoder.layer.11.output.LayerNorm.weight', 'bert.encoder.layer.11.output.LayerNorm.bias', 'bert.encoder.layer.11.intermediate_query.dense.weight', 'bert.encoder.layer.11.intermediate_query.dense.bias', 'bert.encoder.layer.11.output_query.dense.weight', 'bert.encoder.layer.11.output_query.dense.bias', 'bert.encoder.layer.11.output_query.LayerNorm.weight', 'bert.encoder.layer.11.output_query.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Learn the rest parts in Bert: ['bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias']\n",
      "Freeze the pretrained parts in Bert: 273\n",
      "Learn the rest parts in Bert: 60\n",
      "=> loaded resume checkpoint 'pretrained_models/videorecap/videorecap_clip.pt' (epoch 5)\n"
     ]
    }
   ],
   "source": [
    "# Create model and tokenizer\n",
    "ckpt_path = 'pretrained_models/videorecap/videorecap_clip.pt'\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "old_args = ckpt['args']\n",
    "old_args.video_feature_type = 'pixel'  \n",
    "old_args.num_video_feat=4                     # number of frames per clip caption\n",
    "crop_size = 224\n",
    "transform = transforms.Compose([\n",
    "        Permute([3, 0, 1, 2]),  # T H W C -> C T H W\n",
    "        transforms.Resize(crop_size),\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms_video.NormalizeVideo(mean=[108.3272985, 116.7460125, 104.09373615000001], std=[68.5005327, 66.6321579, 70.32316305]),\n",
    "    ])\n",
    "#tokenizer = AutoTokenizer.from_pretrained(old_args.decoder_name)\n",
    "state_dict = OrderedDict()\n",
    "for k, v in ckpt['state_dict'].items():\n",
    "    state_dict[k.replace('module.', '')] = v\n",
    "\n",
    "print(\"=> Creating model\")\n",
    "model = VideoRecap(old_args, eval_only=True)\n",
    "model = model.cuda()\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "print(\"=> loaded resume checkpoint '{}' (epoch {})\".format(ckpt_path, ckpt['epoch']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad0c3a15-d56a-40fa-83dc-d64c5e879eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video length 147.8 seconds\n",
      "number of captions 37\n",
      "[['clientVid1', 0.0, 4.0], ['clientVid1', 4.0, 8.0], ['clientVid1', 8.0, 12.0], ['clientVid1', 12.0, 16.0], ['clientVid1', 16.0, 20.0], ['clientVid1', 20.0, 24.0], ['clientVid1', 24.0, 28.0], ['clientVid1', 28.0, 32.0], ['clientVid1', 32.0, 36.0], ['clientVid1', 36.0, 40.0], ['clientVid1', 40.0, 44.0], ['clientVid1', 44.0, 48.0], ['clientVid1', 48.0, 52.0], ['clientVid1', 52.0, 56.0], ['clientVid1', 56.0, 60.0], ['clientVid1', 60.0, 64.0], ['clientVid1', 64.0, 68.0], ['clientVid1', 68.0, 72.0], ['clientVid1', 72.0, 76.0], ['clientVid1', 76.0, 80.0], ['clientVid1', 80.0, 84.0], ['clientVid1', 84.0, 88.0], ['clientVid1', 88.0, 92.0], ['clientVid1', 92.0, 96.0], ['clientVid1', 96.0, 100.0], ['clientVid1', 100.0, 104.0], ['clientVid1', 104.0, 108.0], ['clientVid1', 108.0, 112.0], ['clientVid1', 112.0, 116.0], ['clientVid1', 116.0, 120.0], ['clientVid1', 120.0, 124.0], ['clientVid1', 124.0, 128.0], ['clientVid1', 128.0, 132.0], ['clientVid1', 132.0, 136.0], ['clientVid1', 136.0, 140.0], ['clientVid1', 140.0, 144.0], ['clientVid1', 144.0, 147.8]]\n",
      "37 5\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001924164F760>\n"
     ]
    }
   ],
   "source": [
    "# Create dataset from the video\n",
    "video = VideoFileClip(video_file)\n",
    "print('Video length', video.duration, 'seconds')\n",
    "\n",
    "video_length = video.duration\n",
    "caption_duration = 4                              # Extract clip caption at each 4 seconds\n",
    "old_args.video_loader_type='moviepy'\n",
    "old_args.chunk_len = -1                           # load from raw video\n",
    "old_args.video_feature_path = 'assets'            # path to the video folder \n",
    "metadata = []  \n",
    "for i in np.arange(0, video_length, caption_duration):\n",
    "    metadata.append([vid, i, min(i + caption_duration, video_length)])    # video name is example.mp4 so assuming video id=example\n",
    "print('number of captions', len(metadata))\n",
    "print(metadata)\n",
    "\n",
    "old_args.metadata = metadata\n",
    "dataset = VideoCaptionDataset(old_args, transform=transform)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, \n",
    "                                        num_workers=8, pin_memory=True, drop_last=False)\n",
    "print(len(dataset), len(data_loader))\n",
    "print(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f77eccd-d39f-4602-b352-47c0f22ceb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57ea7bff-ae47-42fc-8960-55d42ca2dae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#C C looks around\n",
      "#C C walks around the house\n",
      "#C C opens the door\n",
      "#C C holds the cup with both hands\n",
      "#C C drinks coffee\n",
      "#C C walks on the field\n",
      "#C C picks a bicycle\n",
      "#C C looks around\n",
      "\n",
      "#C C looks around\n",
      "#C C looks around\n",
      "#C C looks around\n",
      "#C C rides the bicycle\n",
      "#C C points at the man X\n",
      "#C C points at the board\n",
      "#C C passes the paper to his right hand with his left hand\n",
      "#C C looks around\n",
      "\n",
      "#C C looks around\n",
      "#C C looks around\n",
      "#C C climbs down the mountain\n",
      "#C C takes a picture with the phone in her hands\n",
      "#C C looks around the park\n",
      "#C C looks around\n",
      "#C C looks at the boat\n",
      "#C C looks around\n",
      "\n",
      "#C C looks around\n",
      "#C C looks around\n",
      "#C C opens the door\n",
      "#C C looks around the house\n",
      "#C C looks around\n",
      "#C C looks around\n",
      "#C C looks around\n",
      "#C C mixes the seeds\n",
      "\n",
      "#C C lights the fire\n",
      "#C C looks around the fire\n",
      "#C C looks around\n",
      "#C C looks around\n",
      "#C C looks at the mirror\n"
     ]
    }
   ],
   "source": [
    "jj = 0\n",
    "with torch.no_grad():\n",
    "    for data_iter, samples in enumerate(data_loader):\n",
    "        indices = samples['index']\n",
    "        if hasattr(model, \"vision_model\"):\n",
    "            image = samples[\"video_features\"].permute(0, 2, 1, 3, 4).contiguous().cuda()  # BCTHW -> BTCHW\n",
    "            samples[\"video_features\"] = model.vision_model.forward_features(image, use_checkpoint=old_args.use_checkpoint, cls_at_last=False)  # NLD\n",
    "            #print(samples[\"video_features\"])\n",
    "            \n",
    "            # Get tensor and its shape\n",
    "            tensor = samples[\"video_features\"]\n",
    "            tensor_shape = tensor.shape\n",
    "\n",
    "            # Serialize the tensor to bytes and then encode it in base64 to make it JSON-compatible\n",
    "            tensor_bytes = tensor.cpu().numpy().tobytes()\n",
    "            tensor_base64 = base64.b64encode(tensor_bytes).decode('utf-8')  # base64 encoded string\n",
    "\n",
    "            # Get tensor and its shape\n",
    "            index_tensor = samples['index']\n",
    "            index_tensor_shape = index_tensor.shape\n",
    "\n",
    "            # Serialize the tensor to bytes and then encode it in base64 to make it JSON-compatible\n",
    "            index_tensor_bytes = index_tensor.cpu().numpy().tobytes()\n",
    "            index_tensor_base64 = base64.b64encode(index_tensor_bytes).decode('utf-8')  # base64 encoded string \n",
    "            \n",
    "            # Prepare the data to send\n",
    "            data = {\n",
    "                \"feature_tensor\": tensor_base64,\n",
    "                \"feature_tensor_shape\": list(tensor_shape),\n",
    "                \"index_tensor\": index_tensor_base64,\n",
    "                \"index_tensor_shape\": list(index_tensor_shape),\n",
    "                \"jj\": jj\n",
    "            }\n",
    "\n",
    "            #Send the tensor and shape to the server in the body of a POST request\n",
    "            response = requests.post(\n",
    "                \"http://127.0.0.1:8000/upload_tensor\",\n",
    "                json=data  # send as JSON body\n",
    "            )\n",
    "\n",
    "            print(response.json())\n",
    "            jj+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1457d00-29ea-4e6d-bbff-d4af2bede501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2733a213-6abc-4e8b-96e4-adeb09ca0505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
